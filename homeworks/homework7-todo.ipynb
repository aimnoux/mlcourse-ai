{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание 7. Обучение без учителя"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом задании мы рассмотрим, как работают методы снижения размерности и кластеризации. Заодно ещё раз попрактикуемся в задаче классификации.\n",
    "\n",
    "Мы будем работать с датасетом [Samsung Human Activity Recognition](https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones). Скачайте данные [здесь](https://drive.google.com/file/d/14RukQ0ylM2GCdViUHBBjZ2imCaYcjlux/view?usp=sharing). Данные получены с акселерометров и гироскопов мобильных телефонов Samsung Galaxy S3 (подробнее о признаках по ссылке выше), также известен тип активности человека с телефоном в кармане — ходил ли он, стоял, лежал, сидел или поднимался/спускался по лестнице.\n",
    "\n",
    "Сначала мы сделаем вид, что тип активности нам неизвестен, и попытаемся кластеризовать людей исключительно на основе имеющихся признаков. Затем решим задачу определения типа физической активности как задачу классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use(['seaborn-v0_8-darkgrid'])\n",
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, SpectralClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "RANDOM_STATE = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# при необходимости измените путь\n",
    "PATH_TO_SAMSUNG_DATA = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.loadtxt(os.path.join(PATH_TO_SAMSUNG_DATA, \"samsung_train.txt\"))\n",
    "y_train = np.loadtxt(os.path.join(PATH_TO_SAMSUNG_DATA,\n",
    "                                  \"samsung_train_labels.txt\")).astype(int)\n",
    "\n",
    "X_test = np.loadtxt(os.path.join(PATH_TO_SAMSUNG_DATA, \"samsung_test.txt\"))\n",
    "y_test = np.loadtxt(os.path.join(PATH_TO_SAMSUNG_DATA,\n",
    "                                  \"samsung_test_labels.txt\")).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверяем размерности\n",
    "assert(X_train.shape == (7352, 561) and y_train.shape == (7352,))\n",
    "assert(X_test.shape == (2947, 561) and y_test.shape == (2947,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для кластеризации вектор целевой переменной не нужен, поэтому будем работать с объединением обучающей и тестовой выборок. Объедините `X_train` с `X_test`, и `y_train` с `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определите количество уникальных значений меток целевого класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_classes = np.unique(y).size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Эти метки соответствуют:](https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.names)\n",
    "- 1 – ходьба\n",
    "- 2 – подъём по лестнице\n",
    "- 3 – спуск по лестнице\n",
    "- 4 – сидение\n",
    "- 5 – стояние\n",
    "- 6 – лежание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отмасштабируйте выборку с помощью `StandardScaler` с параметрами по умолчанию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Снизьте число измерений с помощью PCA, оставив столько компонент, сколько необходимо для объяснения как минимум 90% дисперсии исходных (масштабированных) данных. Используйте масштабированный датасет и зафиксируйте `random_state` (константа RANDOM_STATE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код здесь\n",
    "# pca = \n",
    "# X_pca = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос 1:**\n",
    "\n",
    "Какое минимальное число главных компонент необходимо для покрытия 90% дисперсии исходных (масштабированных) данных?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Варианты ответа:**\n",
    "- 56\n",
    "- 65\n",
    "- 66\n",
    "- 193"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос 2:**\n",
    "\n",
    "Какой процент дисперсии покрывается первой главной компонентой? Округлите до ближайшего процента.\n",
    "\n",
    "**Варианты ответа:**\n",
    "- 45\n",
    "- 51\n",
    "- 56\n",
    "- 61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируйте данные в проекции на первые две главные компоненты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код здесь\n",
    "# plt.scatter(, , c=y, s=20, cmap='viridis');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос 3:**\n",
    "\n",
    "Если всё сделано правильно, вы увидите несколько кластеров, почти идеально разделённых друг от друга. Какие типы активности входят в эти кластеры?\n",
    "\n",
    "**Варианты ответа:**\n",
    "- 1 кластер: все 6 активностей\n",
    "- 2 кластера: (ходьба, подъём по лестнице, спуск по лестнице) и (сидение, стояние, лежание)\n",
    "- 3 кластера: (ходьба), (подъём по лестнице, спуск по лестнице) и (сидение, стояние, лежание)\n",
    "- 6 кластеров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполните кластеризацию методом `KMeans`, обучив модель на данных со сниженной размерностью (после PCA). В данном случае мы подскажем искать ровно 6 кластеров, но в общем случае мы не будем знать, сколько кластеров искать.\n",
    "\n",
    "Параметры:\n",
    "\n",
    "- **n_clusters** = n_classes (количество уникальных меток целевого класса)\n",
    "- **n_init** = 100\n",
    "- **random_state** = RANDOM_STATE (для воспроизводимости результата)\n",
    "\n",
    "Остальные параметры оставьте по умолчанию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируйте данные в проекции на первые две главные компоненты. Раскрасьте точки в соответствии с полученными кластерами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код здесь\n",
    "# plt.scatter(, , c=cluster_labels, s=20, cmap='viridis');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрите на соответствие между метками кластеров и исходными метками классов, и на каких видах активности алгоритм `KMeans` ошибается."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tab = pd.crosstab(y, cluster_labels, margins=True)\n",
    "# tab.index = ['ходьба', 'подъём по лестнице',\n",
    "#             'спуск по лестнице', 'сидение', 'стояние', 'лежание', 'всего']\n",
    "# tab.columns = ['cluster' + str(i + 1) for i in range(6)] + ['всего']\n",
    "# tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что для каждого класса (т.е. каждой активности) есть несколько кластеров. Посмотрим на максимальную долю объектов одного класса, отнесённых к одному кластеру. Это будет простая метрика, характеризующая, насколько легко класс отделяется от других при кластеризации.\n",
    "\n",
    "Пример: если для класса «спуск по лестнице» (1406 экземпляров) распределение по кластерам таково:\n",
    " - кластер 1 — 900\n",
    " - кластер 3 — 500\n",
    " - кластер 6 — 6,\n",
    "\n",
    "то такая доля составит 900/1406 $\\approx$ 0.64.\n",
    "\n",
    "**Вопрос 4:**\n",
    "\n",
    "Какая активность лучше всего отделяется от остальных по описанной выше метрике?\n",
    "\n",
    "**Варианты ответа:**\n",
    "- ходьба\n",
    "- стояние\n",
    "- спуск по лестнице\n",
    "- все три варианта неверны"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что KMeans не очень хорошо различает активности. Используйте метод «локтя» для выбора оптимального числа кластеров. Параметры алгоритма и используемые данные те же, что и раньше, меняем только `n_clusters`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ваш код здесь\n",
    "# inertia = []\n",
    "# for k in tqdm_notebook(range(1, n_classes + 1)):\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос 5:**\n",
    "\n",
    "Сколько кластеров можно выбрать по методу «локтя»?\n",
    "\n",
    "**Варианты ответа:**\n",
    "- 1\n",
    "- 2\n",
    "- 3\n",
    "- 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем другой алгоритм кластеризации, описанный в статье — агломеративную кластеризацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ag = AgglomerativeClustering(n_clusters=n_classes, \n",
    "#                              linkage='ward').fit(X_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассчитайте Adjusted Rand Index (`sklearn.metrics`) для полученной кластеризации и для `KMeans` с параметрами из вопроса 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос 6:**\n",
    "\n",
    "Выберите все верные утверждения.\n",
    "\n",
    "**Варианты ответа:**\n",
    "- По ARI, KMeans справился с кластеризацией хуже, чем агломеративная кластеризация\n",
    "- Для ARI неважно, какие метки присвоены кластеру, важно лишь разбиение объектов на кластеры\n",
    "- В случае случайного разбиения на кластеры ARI будет близок к нулю"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно заметить, что задача решается не очень хорошо, когда мы пытаемся выделить несколько кластеров (> 2). Теперь решим задачу классификации, учитывая, что данные размечены.\n",
    "\n",
    "Для классификации используем метод опорных векторов — класс `sklearn.svm.LinearSVC`. В рамках этого курса мы не изучали этот алгоритм отдельно, но он хорошо известен и можно почитать о нём, например, [здесь](http://cs231n.github.io/linear-classify/#svmvssoftmax).\n",
    "\n",
    "Выберите гиперпараметр `C` для `LinearSVC` с помощью `GridSearchCV`.\n",
    "\n",
    "- Обучите новый `StandardScaler` на обучающей выборке (со всеми исходными признаками), примените масштабирование к тестовой выборке\n",
    "- В `GridSearchCV` укажите `cv` = 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ваш код здесь\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled =\n",
    "# X_test_scaled = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = LinearSVC(random_state=RANDOM_STATE)\n",
    "svc_params = {'C': [0.001, 0.01, 0.1, 1, 10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # ваш код здесь\n",
    "# best_svc = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_svc.best_params_, best_svc.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос 7:**\n",
    "\n",
    "Какое значение гиперпараметра `C` оказалось лучшим по результатам кросс-валидации?\n",
    "\n",
    "**Варианты ответа:**\n",
    "- 0.001\n",
    "- 0.01\n",
    "- 0.1\n",
    "- 1\n",
    "- 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_predicted = best_svc.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tab = pd.crosstab(y_test, y_predicted, margins=True)\n",
    "# tab.index = ['ходьба', 'подъём по лестнице',\n",
    "#              'спуск по лестнице', 'сидение', 'стояние', 'лежание', 'всего']\n",
    "# tab.columns = ['ходьба', 'подъём по лестнице',\n",
    "#              'спуск по лестнице', 'сидение', 'стояние', 'лежание', 'всего']\n",
    "# tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос 8:**\n",
    "\n",
    "Какой тип активности хуже всего определяется SVM по precision? По recall?\n",
    "\n",
    "**Варианты ответа:**\n",
    "- precision — подъём по лестнице, recall — лежание\n",
    "- precision — лежание, recall — сидение\n",
    "- precision — ходьба, recall — ходьба\n",
    "- precision — стояние, recall — сидение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, сделайте то же самое, что и в вопросе 7, но с применением PCA.\n",
    "\n",
    "- Используйте `X_train_scaled` и `X_test_scaled`\n",
    "- Обучите тот же PCA, что и раньше, на масштабированной обучающей выборке, примените преобразование к тестовой\n",
    "- Выберите гиперпараметр `C` через кросс-валидацию на обучающей выборке с PCA-преобразованием. Вы заметите, насколько быстрее это работает.\n",
    "\n",
    "**Вопрос 9:**\n",
    "\n",
    "Какова разница между лучшим качеством (accuracy) по кросс-валидации при использовании всех 561 исходных признаков и при применении метода главных компонент? Округлите до ближайшего процента.\n",
    "\n",
    "**Варианты ответа:**\n",
    "- качество одинаковое\n",
    "- 2%\n",
    "- 4%\n",
    "- 10%\n",
    "- 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос 10:**\n",
    "\n",
    "Выберите все верные утверждения:\n",
    "\n",
    "**Варианты ответа:**\n",
    "- Метод главных компонент в данном случае позволил сократить время обучения модели, при этом качество (средняя accuracy по кросс-валидации) сильно пострадало, более чем на 10%\n",
    "- PCA можно использовать для визуализации данных, но для этой задачи есть лучшие методы, например t-SNE. Однако PCA имеет меньшую вычислительную сложность\n",
    "- PCA строит линейные комбинации исходных признаков, и в некоторых приложениях они могут быть плохо интерпретируемы человеком"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
