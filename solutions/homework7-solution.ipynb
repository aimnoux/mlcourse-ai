{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание 7. Обучение без учителя. Решение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом задании мы рассмотрим, как работают методы снижения размерности и кластеризации. Заодно ещё раз попрактикуемся в задаче классификации.\n",
    "\n",
    "Мы будем работать с датасетом [Samsung Human Activity Recognition](https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones). Скачайте данные [здесь](https://drive.google.com/file/d/14RukQ0ylM2GCdViUHBBjZ2imCaYcjlux/view?usp=sharing). Данные получены с акселерометров и гироскопов мобильных телефонов Samsung Galaxy S3, также известен тип активности человека с телефоном в кармане.\n",
    "\n",
    "Сначала мы сделаем вид, что тип активности нам неизвестен, и попытаемся кластеризовать людей исключительно на основе имеющихся признаков. Затем решим задачу определения типа физической активности как задачу классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use(['seaborn-v0_8-darkgrid'])\n",
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, SpectralClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "RANDOM_STATE = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# при необходимости измените путь\n",
    "PATH_TO_SAMSUNG_DATA = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.loadtxt(os.path.join(PATH_TO_SAMSUNG_DATA, \"samsung_train.txt\"))\n",
    "y_train = np.loadtxt(os.path.join(PATH_TO_SAMSUNG_DATA,\n",
    "                                  \"samsung_train_labels.txt\")).astype(int)\n",
    "\n",
    "X_test = np.loadtxt(os.path.join(PATH_TO_SAMSUNG_DATA, \"samsung_test.txt\"))\n",
    "y_test = np.loadtxt(os.path.join(PATH_TO_SAMSUNG_DATA,\n",
    "                                  \"samsung_test_labels.txt\")).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверяем размерности\n",
    "assert(X_train.shape == (7352, 561) and y_train.shape == (7352,))\n",
    "assert(X_test.shape == (2947, 561) and y_test.shape == (2947,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для кластеризации вектор целевой переменной не нужен, поэтому будем работать с объединением обучающей и тестовой выборок. Объедините `X_train` с `X_test`, и `y_train` с `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack([X_train, X_test])\n",
    "y = np.hstack([y_train, y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определите количество уникальных значений меток целевого класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = np.unique(y).size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Эти метки соответствуют:](https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.names)\n",
    "- 1 – ходьба\n",
    "- 2 – подъём по лестнице\n",
    "- 3 – спуск по лестнице\n",
    "- 4 – сидение\n",
    "- 5 – стояние\n",
    "- 6 – лежание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отмасштабируйте выборку с помощью `StandardScaler` с параметрами по умолчанию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Снизьте число измерений с помощью PCA, оставив столько компонент, сколько необходимо для объяснения как минимум 90% дисперсии исходных (масштабированных) данных. Используйте масштабированный датасет и зафиксируйте `random_state` (константа RANDOM_STATE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.9, random_state=RANDOM_STATE).fit(X_scaled)\n",
    "X_pca = pca.transform(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос 1:**\n",
    "\n",
    "Какое минимальное число главных компонент необходимо для покрытия 90% дисперсии исходных (масштабированных) данных?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответ:** 65"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос 2:**\n",
    "\n",
    "Какой процент дисперсии покрывается первой главной компонентой? Округлите до ближайшего процента.\n",
    "\n",
    "**Ответ:** 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(float(pca.explained_variance_ratio_[0] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируйте данные в проекции на первые две главные компоненты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, s=20, cmap='viridis');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос 3:**\n",
    "\n",
    "Если всё сделано правильно, вы увидите несколько кластеров, почти идеально разделённых друг от друга. Какие типы активности входят в эти кластеры?\n",
    "\n",
    "**Ответ:** 2 кластера: (ходьба, подъём по лестнице, спуск по лестнице) и (сидение, стояние, лежание)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполните кластеризацию методом `KMeans`, обучив модель на данных со сниженной размерностью (после PCA).\n",
    "\n",
    "Параметры:\n",
    "- **n_clusters** = n_classes\n",
    "- **n_init** = 100\n",
    "- **random_state** = RANDOM_STATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=n_classes, n_init=100, \n",
    "                random_state=RANDOM_STATE)\n",
    "kmeans.fit(X_pca)\n",
    "cluster_labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируйте данные в проекции на первые две главные компоненты, раскрасив точки по кластерам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=cluster_labels, s=20,  \n",
    "            cmap='viridis');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрите на соответствие между метками кластеров и исходными метками классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = pd.crosstab(y, cluster_labels, margins=True)\n",
    "tab.index = ['ходьба', 'подъём по лестнице',\n",
    "            'спуск по лестнице', 'сидение', 'стояние', 'лежание', 'всего']\n",
    "tab.columns = ['cluster' + str(i + 1) for i in range(6)] + ['всего']\n",
    "tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос 4:**\n",
    "\n",
    "Какая активность лучше всего отделяется от остальных по описанной выше метрике?\n",
    "\n",
    "**Ответ:** все три варианта неверны (лучше всего отделяется «подъём по лестнице»)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(tab.iloc[:-1,:-1].max(axis=1).values / \n",
    "          tab.iloc[:-1,-1].values, index=tab.index[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что KMeans не очень хорошо различает активности. Используйте метод «локтя» для выбора оптимального числа кластеров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inertia = []\n",
    "for k in tqdm_notebook(range(1, n_classes + 1)):\n",
    "    kmeans = KMeans(n_clusters=k, n_init=100, \n",
    "                    random_state=RANDOM_STATE).fit(X_pca)\n",
    "    inertia.append(np.sqrt(kmeans.inertia_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, 7), inertia, marker='s');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычислим $D(k)$, как описано в [статье](https://www.kaggle.com/kashnitsky/topic-7-unsupervised-learning-pca-and-clustering) в разделе «Выбор числа кластеров для KMeans»."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for k in range(2, 6):\n",
    "    i = k - 1\n",
    "    d[k] = (inertia[i] - inertia[i + 1]) / (inertia[i - 1] - inertia[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос 5:**\n",
    "\n",
    "Сколько кластеров можно выбрать по методу «локтя»?\n",
    "\n",
    "**Ответ:** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем другой алгоритм кластеризации — агломеративную кластеризацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag = AgglomerativeClustering(n_clusters=n_classes, \n",
    "                             linkage='ward').fit(X_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассчитайте Adjusted Rand Index (`sklearn.metrics`) для полученной кластеризации и для `KMeans`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('KMeans: ARI =', metrics.adjusted_rand_score(y, cluster_labels))\n",
    "print('Agglomerative Clustering: ARI =', \n",
    "      metrics.adjusted_rand_score(y, ag.labels_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос 6:**\n",
    "\n",
    "Выберите все верные утверждения.\n",
    "\n",
    "**Ответ:**\n",
    "- По ARI, KMeans справился с кластеризацией хуже, чем агломеративная кластеризация — **верно**\n",
    "- Для ARI неважно, какие метки присвоены кластеру, важно лишь разбиение объектов на кластеры — **верно**\n",
    "- В случае случайного разбиения на кластеры ARI будет близок к нулю — **верно**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь решим задачу классификации, учитывая, что данные размечены.\n",
    "\n",
    "Для классификации используем метод опорных векторов — класс `sklearn.svm.LinearSVC`.\n",
    "\n",
    "Выберите гиперпараметр `C` для `LinearSVC` с помощью `GridSearchCV`.\n",
    "\n",
    "- Обучите новый `StandardScaler` на обучающей выборке, примените масштабирование к тестовой\n",
    "- В `GridSearchCV` укажите `cv` = 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = LinearSVC(random_state=RANDOM_STATE)\n",
    "svc_params = {'C': [0.001, 0.01, 0.1, 1, 10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "best_svc = GridSearchCV(svc, svc_params, n_jobs=1, cv=3, verbose=1)\n",
    "best_svc.fit(X_train_scaled, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_svc.best_params_, best_svc.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос 7:**\n",
    "\n",
    "Какое значение гиперпараметра `C` оказалось лучшим?\n",
    "\n",
    "**Ответ:** 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = best_svc.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = pd.crosstab(y_test, y_predicted, margins=True)\n",
    "tab.index = ['ходьба', 'подъём по лестнице',\n",
    "             'спуск по лестнице', 'сидение', 'стояние', 'лежание', 'всего']\n",
    "tab.columns = ['ходьба', 'подъём по лестнице',\n",
    "             'спуск по лестнице', 'сидение', 'стояние', 'лежание', 'всего']\n",
    "tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, задача классификации решается достаточно хорошо."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос 8:**\n",
    "\n",
    "Путает ли SVM классы внутри групп активностей, выявленных ранее (в вопросе 3)?\n",
    "\n",
    "**Ответ:** Да. Классификатор решил задачу хорошо, но не идеально."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, сделайте то же самое, что и в вопросе 7, но с применением PCA.\n",
    "\n",
    "**Вопрос 9:**\n",
    "\n",
    "Какова разница между лучшим качеством (accuracy) по кросс-валидации при использовании всех 561 исходных признаков и при применении PCA? Округлите до ближайшего процента.\n",
    "\n",
    "**Ответ:** 4%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "pca = PCA(n_components=0.9, random_state=RANDOM_STATE)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = LinearSVC(random_state=RANDOM_STATE)\n",
    "svc_params = {'C': [0.001, 0.01, 0.1, 1, 10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "best_svc_pca = GridSearchCV(svc, svc_params, n_jobs=1, cv=3, verbose=1)\n",
    "best_svc_pca.fit(X_train_pca, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_svc_pca.best_params_, best_svc_pca.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат с PCA хуже на 4% по доле правильных ответов на кросс-валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(100 * (best_svc_pca.best_score_ - best_svc.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос 10:**\n",
    "\n",
    "Выберите все верные утверждения:\n",
    "\n",
    "**Ответ:**\n",
    "- PCA можно использовать для визуализации данных, но для этой задачи есть лучшие методы, например t-SNE. Однако PCA имеет меньшую вычислительную сложность — **верно**\n",
    "- PCA строит линейные комбинации исходных признаков, и в некоторых приложениях они могут быть плохо интерпретируемы человеком — **верно**\n",
    "\n",
    "### Комментарий:\n",
    "1. PCA позволила значительно сократить время обучения модели, но качество пострадало не так сильно — всего на 4%\n",
    "2. Для визуализации многомерных данных лучше использовать методы manifold learning, в частности t-SNE\n",
    "3. Линейные комбинации признаков, которые строит PCA, плохо интерпретируются человеком, например: 0.574 * salary + 0.234 * num_children\n",
    "4. SVM и KMeans в принципе не следует сравнивать напрямую — они решают разные задачи"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
