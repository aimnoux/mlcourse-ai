{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Домашнее задание №10\n",
    "## <center> Градиентный бустинг\n",
    "\n",
    "Ваша задача — побить как минимум 2 бенчмарка в этом [соревновании на Kaggle](https://www.kaggle.com/c/flight-delays-spring-2018). Здесь не будет подробных инструкций. Мы лишь кратко опишем, как был достигнут второй бенчмарк с помощью Xgboost. Надеемся, что на этом этапе курса достаточно бегло взглянуть на данные, чтобы понять: это тот тип задачи, где градиентный бустинг покажет себя хорошо. Скорее всего, это будет Xgboost, однако здесь много категориальных признаков.\n",
    "\n",
    "<img src=https://habrastorage.org/webt/fs/42/ms/fs42ms0r7qsoj-da4x7yfntwrbq.jpeg width=40% />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/flight_delays_train.csv')\n",
    "test = pd.read_csv('../data/flight_delays_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По времени вылета, коду перевозчика, аэропорту отправления, пункту назначения и дистанции перелёта необходимо предсказать задержку вылета более чем на 15 минут. В качестве простейшего бенчмарка возьмём классификатор Xgboost с двумя признаками, которые проще всего использовать: DepTime и Distance. Такая модель даёт 0.68202 на лидерборде."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[['Distance', 'DepTime']].values\n",
    "y_train = train['dep_delayed_15min'].map({'Y': 1, 'N': 0}).values\n",
    "X_test = test[['Distance', 'DepTime']].values\n",
    "\n",
    "X_train_part, X_valid, y_train_part, y_valid = \\\n",
    "    train_test_split(X_train, y_train, \n",
    "                     test_size=0.3, random_state=17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим Xgboost с параметрами по умолчанию на части данных и оценим ROC AUC на отложенной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier(seed=17)\n",
    "\n",
    "xgb_model.fit(X_train_part, y_train_part)\n",
    "xgb_valid_pred = xgb_model.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "roc_auc_score(y_valid, xgb_valid_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь сделаем то же самое на всей обучающей выборке, сделаем предсказания для тестовой выборки и сформируем файл для отправки. Так вы побьёте первый бенчмарк."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_test_pred = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "pd.Series(xgb_test_pred, \n",
    "          name='dep_delayed_15min').to_csv('xgb_2feat.csv', \n",
    "                                           index_label='id', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Второй бенчмарк в лидерборде был достигнут следующим образом:\n",
    "\n",
    "- Признаки `Distance` и `DepTime` были взяты без изменений\n",
    "- Из признаков `Origin` и `Dest` был создан признак `Flight`\n",
    "- Признаки `Month`, `DayofMonth`, `DayOfWeek`, `UniqueCarrier` и `Flight` были преобразованы с помощью OHE (`LabelBinarizer`)\n",
    "- Были обучены логистическая регрессия и градиентный бустинг (xgboost). Гиперпараметры xgboost настраивались через кросс-валидацию. Сначала оптимизировались гиперпараметры, отвечающие за сложность модели, затем число деревьев было зафиксировано на 500, и настраивался шаг обучения.\n",
    "- Предсказанные вероятности были получены через кросс-валидацию с помощью `cross_val_predict`. Линейная смесь предсказаний логистической регрессии и градиентного бустинга была задана в форме $w_1 * p_{logit} + (1 - w_1) * p_{xgb}$, где $p_{logit}$ — вероятность класса 1, предсказанная логистической регрессией, а $p_{xgb}$ — то же для xgboost. Вес $w_1$ подбирался вручную.\n",
    "- Аналогичная комбинация предсказаний была сделана для тестовой выборки.\n",
    "\n",
    "Следовать в точности этим шагам необязательно. Это лишь описание того, как результат был получен автором задания. Возможно, вы захотите пойти другим путём — например, добавить пару хороших признаков и обучить случайный лес из тысячи деревьев.\n",
    "\n",
    "Удачи!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
